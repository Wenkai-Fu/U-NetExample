{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainingExample.ipynb","provenance":[],"authorship_tag":"ABX9TyO508OF35MEwQ1ShY6OmsdZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"l4ENCd91nkLU","colab_type":"text"},"source":["This script was tested in google colab. Before starting, please cd to the folder where the script is. If missing module error happens, please install the corresponding library in this runtime. Please also don't forget to enable GPU in Runtime/Change runtime type"]},{"cell_type":"code","metadata":{"id":"dZmmzJQnnWMQ","colab_type":"code","outputId":"cabe8a2f-df3d-43d2-88ea-8947f2812951","executionInfo":{"status":"ok","timestamp":1591568333541,"user_tz":300,"elapsed":1347,"user":{"displayName":"Lance","photoUrl":"","userId":"05879884977853866733"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#cd to the script folder\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('drive/My Drive/Machine Learning')#Need to change the address to where your script is\n","os.listdir('.')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['data', 'log.csv', 'TrainingExample.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"m_MgGkGVqHgY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"213390b0-ee57-40c2-cd3f-5209027c045b","executionInfo":{"status":"ok","timestamp":1591568344861,"user_tz":300,"elapsed":8759,"user":{"displayName":"Lance","photoUrl":"","userId":"05879884977853866733"}}},"source":["#load training dataset\n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","\n","nameList = os.listdir('data/train')\n","trainSize = len(nameList)\n","imgs = np.ndarray((trainSize,512,512,1), dtype='float32')\n","labels = np.ndarray((trainSize,512,512,1), dtype='float32')\n","for i in range(len(nameList)):\n","  img = load_img('data/train/' + str(i+1) + '.tif',grayscale = True)\n","  label = load_img('data/label/' + str(i+1)+ '.tif' ,grayscale = True)\n","  img = img_to_array(img).astype('float32')\n","  label = img_to_array(label).astype('float32')\n","  img -= img.mean()\n","  img /= img.std()\n","  imgs[i] = img\n","  labels[i] = label\n","  if i % 100 == 0:\n","    print('Done: {0}/{1} images'.format(i, len(imgs)))\n","labels /= 255\n","labels[labels > 0.5] = 1\n","labels[labels <= 0.5] = 0\n","labels = np.reshape(1-labels,[-1,262144,1])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"stream","text":["Done: 0/1000 images\n","Done: 100/1000 images\n","Done: 200/1000 images\n","Done: 300/1000 images\n","Done: 400/1000 images\n","Done: 500/1000 images\n","Done: 600/1000 images\n","Done: 700/1000 images\n","Done: 800/1000 images\n","Done: 900/1000 images\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"exYcPI9bsxM0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c896021a-ba7c-4f53-bd8f-8fe378f4a86d","executionInfo":{"status":"ok","timestamp":1591570588686,"user_tz":300,"elapsed":2230756,"user":{"displayName":"Lance","photoUrl":"","userId":"05879884977853866733"}}},"source":["#training\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger\n","from keras import backend as keras\n","from keras.initializers import *\n","def get_unet():\n","\t\tinputs = Input((512,512,1))\n","\t\tconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","\t\tprint (\"conv1 shape:\",conv1.shape)\n","\t\tconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","\t\tprint (\"conv1 shape:\",conv1.shape)\n","\t\tpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\t\tprint (\"pool1 shape:\",pool1.shape)\n","\n","\t\tconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","\t\tprint (\"conv2 shape:\",conv2.shape)\n","\t\tconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","\t\tprint (\"conv2 shape:\",conv2.shape)\n","\t\tpool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\t\tprint (\"pool2 shape:\",pool2.shape)\n","\n","\t\tconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","\t\tprint (\"conv3 shape:\",conv3.shape)\n","\t\tconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","\t\tprint (\"conv3 shape:\",conv3.shape)\n","\t\tpool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\t\tprint (\"pool3 shape:\",pool3.shape)\n","\n","\t\tconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","\t\tconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","\t\tdrop4 = Dropout(0.5)(conv4)\n","\t\tpool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","\t\tconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","\t\tconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","\t\tdrop5 = Dropout(0.5)(conv5)\n","\n","\t\tup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","\t\tmerge6 = concatenate([drop4,up6],axis=3)\n","\t\tconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","\t\tconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","\t\tup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","\t\tmerge7 = concatenate([conv3,up7], axis = 3)\n","\t\tconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","\t\tconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","\t\tup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","\t\tmerge8 = concatenate([conv2,up8], axis = 3)\n","\t\tconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","\t\tconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","\t\tup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","\t\tmerge9 = concatenate([conv1,up9], axis = 3)\n","\t\tconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","\t\tconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","\t\tconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","\t\tconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\t\treshape = Reshape((262144,1))(conv10)\n","\t\tmodel = Model(inputs = inputs, outputs = reshape)\n","\t\tmodel.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\t\treturn model\n","\n","model = get_unet()\n","model_checkpoint = ModelCheckpoint('model.hdf5', monitor='loss',verbose=1, save_best_only=True)\n","csv_logger = CSVLogger('log.csv', append=False, separator=',')\n","model.summary()\n","model.fit(imgs, labels, batch_size=2, epochs=15, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint,csv_logger])\n","print('Fitting model...')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["conv1 shape: (None, 512, 512, 64)\n","conv1 shape: (None, 512, 512, 64)\n","pool1 shape: (None, 256, 256, 64)\n","conv2 shape: (None, 256, 256, 128)\n","conv2 shape: (None, 256, 256, 128)\n","pool2 shape: (None, 128, 128, 128)\n","conv3 shape: (None, 128, 128, 256)\n","conv3 shape: (None, 128, 128, 256)\n","pool3 shape: (None, 64, 64, 256)\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 512, 512, 1)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 512, 512, 64) 640         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 512, 512, 64) 36928       conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 256, 256, 128 147584      conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 128, 128, 256 590080      conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 64, 64, 512)  2359808     conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 64, 64, 512)  0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 512)  0           dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 1024) 9438208     conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 32, 32, 1024) 0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 1024) 0           dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 1024) 0           dropout_1[0][0]                  \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 512 0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 512 0           conv2d_6[0][0]                   \n","                                                                 conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 128, 128, 256 590080      conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 256 0           conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 256 0           conv2d_4[0][0]                   \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 256, 256, 128 295040      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 256, 256, 128 147584      conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 512, 512, 128 0           conv2d_2[0][0]                   \n","                                                                 conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 512, 512, 2)  1154        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 512, 512, 1)  3           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 262144, 1)    0           conv2d_24[0][0]                  \n","==================================================================================================\n","Total params: 31,031,685\n","Trainable params: 31,031,685\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Train on 800 samples, validate on 200 samples\n","Epoch 1/15\n","800/800 [==============================] - 176s 220ms/step - loss: 0.2010 - accuracy: 0.9463 - val_loss: 0.1860 - val_accuracy: 0.9545\n","\n","Epoch 00001: loss improved from inf to 0.20105, saving model to model.hdf5\n","Epoch 2/15\n","800/800 [==============================] - 142s 178ms/step - loss: 0.1771 - accuracy: 0.9600 - val_loss: 0.1692 - val_accuracy: 0.9636\n","\n","Epoch 00002: loss improved from 0.20105 to 0.17709, saving model to model.hdf5\n","Epoch 3/15\n","800/800 [==============================] - 142s 178ms/step - loss: 0.1680 - accuracy: 0.9642 - val_loss: 0.1647 - val_accuracy: 0.9647\n","\n","Epoch 00003: loss improved from 0.17709 to 0.16800, saving model to model.hdf5\n","Epoch 4/15\n","800/800 [==============================] - 142s 178ms/step - loss: 0.1633 - accuracy: 0.9654 - val_loss: 0.1627 - val_accuracy: 0.9645\n","\n","Epoch 00004: loss improved from 0.16800 to 0.16326, saving model to model.hdf5\n","Epoch 5/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1592 - accuracy: 0.9663 - val_loss: 0.1568 - val_accuracy: 0.9667\n","\n","Epoch 00005: loss improved from 0.16326 to 0.15921, saving model to model.hdf5\n","Epoch 6/15\n","800/800 [==============================] - 142s 178ms/step - loss: 0.1558 - accuracy: 0.9667 - val_loss: 0.1538 - val_accuracy: 0.9671\n","\n","Epoch 00006: loss improved from 0.15921 to 0.15577, saving model to model.hdf5\n","Epoch 7/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1521 - accuracy: 0.9674 - val_loss: 0.1516 - val_accuracy: 0.9666\n","\n","Epoch 00007: loss improved from 0.15577 to 0.15213, saving model to model.hdf5\n","Epoch 8/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1488 - accuracy: 0.9679 - val_loss: 0.1483 - val_accuracy: 0.9673\n","\n","Epoch 00008: loss improved from 0.15213 to 0.14882, saving model to model.hdf5\n","Epoch 9/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1458 - accuracy: 0.9682 - val_loss: 0.1462 - val_accuracy: 0.9673\n","\n","Epoch 00009: loss improved from 0.14882 to 0.14581, saving model to model.hdf5\n","Epoch 10/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1422 - accuracy: 0.9689 - val_loss: 0.1454 - val_accuracy: 0.9661\n","\n","Epoch 00010: loss improved from 0.14581 to 0.14221, saving model to model.hdf5\n","Epoch 11/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1391 - accuracy: 0.9694 - val_loss: 0.1415 - val_accuracy: 0.9670\n","\n","Epoch 00011: loss improved from 0.14221 to 0.13908, saving model to model.hdf5\n","Epoch 12/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1358 - accuracy: 0.9700 - val_loss: 0.1402 - val_accuracy: 0.9666\n","\n","Epoch 00012: loss improved from 0.13908 to 0.13580, saving model to model.hdf5\n","Epoch 13/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1323 - accuracy: 0.9707 - val_loss: 0.1373 - val_accuracy: 0.9676\n","\n","Epoch 00013: loss improved from 0.13580 to 0.13234, saving model to model.hdf5\n","Epoch 14/15\n","800/800 [==============================] - 142s 177ms/step - loss: 0.1289 - accuracy: 0.9714 - val_loss: 0.1369 - val_accuracy: 0.9671\n","\n","Epoch 00014: loss improved from 0.13234 to 0.12893, saving model to model.hdf5\n","Epoch 15/15\n","800/800 [==============================] - 142s 178ms/step - loss: 0.1256 - accuracy: 0.9721 - val_loss: 0.1348 - val_accuracy: 0.9664\n","\n","Epoch 00015: loss improved from 0.12893 to 0.12561, saving model to model.hdf5\n","Fitting model...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ewvPAiHtwmzm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"53c5beff-03ff-44af-be62-0799eded1ee0","executionInfo":{"status":"ok","timestamp":1591572294423,"user_tz":300,"elapsed":31846,"user":{"displayName":"Lance","photoUrl":"","userId":"05879884977853866733"}}},"source":["#prediction\n","nameListTest = os.listdir('data/test')\n","testSize = len(nameListTest)\n","tests = np.ndarray((testSize,512,512,1), dtype='float32')\n","print('Loading')\n","for i in range(len(nameListTest)):\n","  img = load_img('data/test/' + str(i+1) + '.tif',grayscale = True)\n","  img = img_to_array(img).astype('float32')\n","  img -= img.mean()\n","  img /= img.std()\n","  tests[i] = img\n","  if (i+1) % 100 == 0:\n","    print('Done: {0}/{1} images'.format(i+1, testSize))\n","model = load_model('model.hdf5')\n","print(\"Network Loaded\")\n","print('Predicting test data')\n","predictions = model.predict(tests, batch_size=1, verbose=1)\n","predictions = np.reshape(predictions, [-1,512,512,1])\n","for i in range(predictions.shape[0]):\n","\t\timg = array_to_img(predictions[i])\n","\t\timg.save(\"data/prediction/{:d}\".format(i)+'.tif')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Loading\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"stream","text":["Done: 100/100 images\n","Net Loaded\n","Predicting test data\n","100/100 [==============================] - 6s 58ms/step\n"],"name":"stdout"}]}]}